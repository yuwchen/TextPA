# TextPA

This code is related to the paper accepted by EMNLP 2025

**Read to Hear: A Zero-Shot Pronunciation Assessment Using Textual Descriptions and LLMs**

<img src="https://github.com/yuwchen/TextPA/blob/main/plt/main.jpg" 
alt="main"  width=80% height=80% /> 

## Data
* [MultiPA data](https://github.com/yuwchen/MultiPA)
* [Speechocean762](https://github.com/jimbozhang/speechocean762)

## References 
* Phonetic aligner: [Charsiu](https://github.com/lingjzhu/charsiu/tree/main)  
* Automatic speech recognition: [Whisper](https://github.com/openai/whisper)  
* Phoneme recognition: [wav2vec](https://huggingface.co/facebook/wav2vec2-lv-60-espeak-cv-ft)  

## Citation
@inproceedings{chen2025textpa,  
title = {Read to Hear: A Zero-Shot Pronunciation Assessment Using Textual Descriptions and LLMs},  
author = {Chen, Yu-Wen and Ma, Melody and Hirschberg, Julia},  
booktitle = {Proc. EMNLP 2025}  
}  
